{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & Querie Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "#get the reddit web scraper library\n",
    "folder_path = os.path.abspath(\"..\")\n",
    "\n",
    "if folder_path not in sys.path:\n",
    "    sys.path.append(folder_path)\n",
    "\n",
    "from database import KnowledgeBase\n",
    "import reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#get queries text example\n",
    "with open(\"../gradio-tests/queries_0a891.json\") as file:\n",
    "    out_json = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Web Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googlesearch import search\n",
    "from datetime import datetime\n",
    "\n",
    "#build database\n",
    "db = KnowledgeBase()\n",
    "#start session\n",
    "db.start_session()\n",
    "\n",
    "#save topic\n",
    "topic = \"javascript\"\n",
    "#get difficulty\n",
    "difficulty = \"beginner\"\n",
    "#get search query\n",
    "search_query = out_json[difficulty][\"query\"]\n",
    "#create search\n",
    "search_results = search(search_query, advanced=True, num_results=5)\n",
    "\n",
    "index = 0\n",
    "#search results\n",
    "results_data = []\n",
    "#loop through results\n",
    "for result in search_results:\n",
    "    index += 1\n",
    "\n",
    "    print(f\"Round {index}\")\n",
    "    if not db.find_url(result.url):\n",
    "        #track current result\n",
    "        curr_data = {}\n",
    "        #save resource url\n",
    "        curr_data[\"resource\"] = result.url\n",
    "        #save resource title\n",
    "        curr_data[\"title\"] = result.title\n",
    "        #save resource description\n",
    "        curr_data[\"description\"] = result.description.replace(\"'\", \"\")\n",
    "        #save resource topic\n",
    "        curr_data[\"topic\"] = topic\n",
    "        #save resource difficulty\n",
    "        curr_data[\"difficulty\"] = difficulty\n",
    "        #save resource validation\n",
    "        curr_data[\"validated\"] = False\n",
    "        #save resource found time\n",
    "        curr_data[\"found_time\"] = datetime.now()\n",
    "        #append data to list\n",
    "        results_data.append(curr_data)\n",
    "    else:\n",
    "        print(f\"Link: {result.url} already exists in database\")\n",
    "        continue\n",
    "\n",
    "    #check to see if we found our five links\n",
    "    if len(results_data) == 5:\n",
    "        break\n",
    "\n",
    "#check to see if we have enough data to push to database\n",
    "if len(results_data) >= 5:\n",
    "    #loop through search results and insert\n",
    "    for data in results_data:\n",
    "        #insert current data into database\n",
    "        db.insert_resource(data)\n",
    "else:\n",
    "    print(\"Not enough data to commit\")\n",
    "\n",
    "#commit changes made in session\n",
    "db.commit_session()\n",
    "#end session\n",
    "db.end_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM-integration",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
